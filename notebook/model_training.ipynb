{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acL_6BjvH0hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cccba23-d2cf-40fd-f0e0-0c9818e3a111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu128)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu128)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (26.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2026.1.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision kagglehub pandas scikit-learn tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "Q0zoTUChM9rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "USE_AMP = torch.cuda.is_available()\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Oi8En-6NFxa",
        "outputId": "3a479b0a-b8e1-4f6a-9305-4bfb7d7f4a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "dataset = kagglehub.dataset_download(\n",
        "    \"xhlulu/140k-real-and-fake-faces\"\n",
        ")\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvwNtII1NJag",
        "outputId": "4d7f5211-6e42-4e0b-b95e-9bb5db66720a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (1.0.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/xhlulu/140k-real-and-fake-faces?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.75G/3.75G [02:54<00:00, 23.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/xhlulu/140k-real-and-fake-faces/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "DATASET_ROOT = dataset\n",
        "\n",
        "train_df = pd.read_csv(f\"{DATASET_ROOT}/train.csv\")\n",
        "valid_df = pd.read_csv(f\"{DATASET_ROOT}/valid.csv\")\n",
        "\n",
        "print(train_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcjLs6zOOivn",
        "outputId": "7e4efe43-c7ab-40e1-9cfa-4e1cab5043bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                      original_path     id  \\\n",
            "0           0  /kaggle/input/flickrfaceshq-dataset-nvidia-par...  31355   \n",
            "1           1  /kaggle/input/flickrfaceshq-dataset-nvidia-par...  02884   \n",
            "2           2  /kaggle/input/flickrfaceshq-dataset-nvidia-par...  33988   \n",
            "3           3  /kaggle/input/flickrfaceshq-dataset-nvidia-par...  53875   \n",
            "4           4  /kaggle/input/flickrfaceshq-dataset-nvidia-par...  24149   \n",
            "\n",
            "   label label_str                  path  \n",
            "0      1      real  train/real/31355.jpg  \n",
            "1      1      real  train/real/02884.jpg  \n",
            "2      1      real  train/real/33988.jpg  \n",
            "3      1      real  train/real/53875.jpg  \n",
            "4      1      real  train/real/24149.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class FaceDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, root_dir, transform=None):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        img_rel_path = row[\"path\"]\n",
        "        label = int(row[\"label\"])\n",
        "\n",
        "        img_path = os.path.join(\n",
        "            self.root_dir,\n",
        "            \"real_vs_fake\",\n",
        "            \"real-vs-fake\",\n",
        "            img_rel_path\n",
        "        )\n",
        "\n",
        "        if not os.path.exists(img_path):\n",
        "            raise FileNotFoundError(img_path)\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "cOJ3nAzy47hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485,0.456,0.406],\n",
        "        std=[0.229,0.224,0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485,0.456,0.406],\n",
        "        std=[0.229,0.224,0.225]\n",
        "    )\n",
        "])"
      ],
      "metadata": {
        "id": "u50A7VVeO34u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = FaceDataset(train_df, DATASET_ROOT, train_transform)\n",
        "valid_dataset = FaceDataset(valid_df, DATASET_ROOT, val_transform)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    valid_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "Bsbm9nDAO9Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "scaler = GradScaler(\"cuda\", enabled=USE_AMP)\n",
        "\n",
        "weights = EfficientNet_B0_Weights.IMAGENET1K_V1\n",
        "model = efficientnet_b0(\n",
        "    weights=EfficientNet_B0_Weights.IMAGENET1K_V1\n",
        ")\n",
        "\n",
        "model.classifier[1] = nn.Sequential(\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(model.classifier[1].in_features, 1)\n",
        ")\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1.0]).to(device))\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n"
      ],
      "metadata": {
        "id": "HBEfNwgzPCKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5521909b-6fa2-4470-eec5-232eaeea213a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 181MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.float().unsqueeze(1).to(device)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        if USE_AMP:\n",
        "            with autocast(\"cuda\"):\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "        else:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n"
      ],
      "metadata": {
        "id": "OuWc5dtt6OIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    preds, targets = [], []\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.float().unsqueeze(1).to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            probs = torch.sigmoid(outputs)\n",
        "\n",
        "            preds.extend(probs.cpu().numpy().ravel())\n",
        "            targets.extend(labels.cpu().numpy().ravel())\n",
        "\n",
        "    preds = np.array(preds)\n",
        "    targets = np.array(targets)\n",
        "\n",
        "    binary_preds = (preds > 0.4).astype(int)\n",
        "\n",
        "    metrics = {\n",
        "        \"acc\": accuracy_score(targets, binary_preds),\n",
        "        \"precision\": precision_score(targets, binary_preds, zero_division=0),\n",
        "        \"recall\": recall_score(targets, binary_preds, zero_division=0),\n",
        "        \"f1\": f1_score(targets, binary_preds, zero_division=0),\n",
        "        \"auc\": roc_auc_score(targets, preds)\n",
        "    }\n",
        "\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "VNI7g8LmAVLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainable = [p for p in model.parameters() if p.requires_grad]\n",
        "print(\"Trainable params:\", len(trainable))\n"
      ],
      "metadata": {
        "id": "YKNXpyj4HZ26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 7\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "    train_loss = train_one_epoch(model, train_loader)\n",
        "    metrics = evaluate(model, val_loader)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "    print(\n",
        "        f\"Val Acc: {metrics['acc']:.4f}, \"\n",
        "        f\"Precision: {metrics['precision']:.4f}, \"\n",
        "        f\"Recall: {metrics['recall']:.4f}, \"\n",
        "        f\"F1: {metrics['f1']:.4f}, \"\n",
        "        f\"AUC: {metrics['auc']:.4f}\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "wmG4Evqi6UA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ef70eae-82b6-4dab-e0c3-1214d9f21705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 3125/3125 [12:31<00:00,  4.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5820\n",
            "Val Acc: 0.7538, Precision: 0.8115, Recall: 0.6612, F1: 0.7287, AUC: 0.8478\n",
            "\n",
            "Epoch 2/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 3125/3125 [12:21<00:00,  4.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5297\n",
            "Val Acc: 0.7729, Precision: 0.8211, Recall: 0.6978, F1: 0.7545, AUC: 0.8641\n",
            "\n",
            "Epoch 3/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 3125/3125 [11:53<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5189\n",
            "Val Acc: 0.7760, Precision: 0.8344, Recall: 0.6887, F1: 0.7546, AUC: 0.8715\n",
            "\n",
            "Epoch 4/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 3125/3125 [11:56<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5139\n",
            "Val Acc: 0.7870, Precision: 0.8325, Recall: 0.7186, F1: 0.7714, AUC: 0.8776\n",
            "\n",
            "Epoch 5/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 3125/3125 [11:55<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5120\n",
            "Val Acc: 0.7909, Precision: 0.8271, Recall: 0.7356, F1: 0.7787, AUC: 0.8804\n",
            "\n",
            "Epoch 6/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 3125/3125 [11:54<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5087\n",
            "Val Acc: 0.7862, Precision: 0.8432, Recall: 0.7032, F1: 0.7668, AUC: 0.8818\n",
            "\n",
            "Epoch 7/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 3125/3125 [11:57<00:00,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.5088\n",
            "Val Acc: 0.7944, Precision: 0.8323, Recall: 0.7373, F1: 0.7819, AUC: 0.8831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"vigilant_eye.pth\")"
      ],
      "metadata": {
        "id": "lLJhst_lUnCS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}